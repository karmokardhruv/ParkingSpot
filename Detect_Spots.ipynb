{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e834cb20-619e-4b2c-91f8-19f0afa41543",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cff7bbe-5b58-4d96-8781-3b02da54c8ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants for SVC model output\n",
    "EMPTY = True\n",
    "NOT_EMPTY = False\n",
    "\n",
    "# Load the SVC model\n",
    "MODEL = pickle.load(open(\"model.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0765b904-1afb-4544-bed4-cf6c8bb5171e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input data\n",
    "mask_path = 'mask_1920_1080.png'\n",
    "video_path = 'parking_1920_1080_loop.mp4'\n",
    "\n",
    "# Read the mask\n",
    "mask = cv2.imread(mask_path, 0)\n",
    "\n",
    "# Capture video from the specified path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Obtain connected components to find parking spots\n",
    "connected_components = cv2.connectedComponentsWithStats(mask, 4, cv2.CV_32S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9470724-99e6-4999-b9f1-0e5c7c618ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "# Function to predict if a parking spot is empty or not\n",
    "def empty_or_not(spot_bgr):\n",
    "    flat_data = []\n",
    "    img_resized = resize(spot_bgr, (15, 15, 3))\n",
    "    flat_data.append(img_resized.flatten())\n",
    "    flat_data = np.array(flat_data)\n",
    "    y_output = MODEL.predict(flat_data)\n",
    "\n",
    "    if y_output == 0:\n",
    "        return EMPTY\n",
    "    else:\n",
    "        return NOT_EMPTY\n",
    "\n",
    "# Function to get parking spot bounding boxes from connected components\n",
    "def get_parking_spots_bboxes(connected_components):\n",
    "    (totalLabels, label_ids, values, centroids) = connected_components\n",
    "    slots = []\n",
    "    coef = 1  # Scaling coefficient\n",
    "\n",
    "    for i in range(1, totalLabels):\n",
    "        # Extract the bounding box coordinates\n",
    "        x1 = int(values[i, cv2.CC_STAT_LEFT] * coef)\n",
    "        y1 = int(values[i, cv2.CC_STAT_TOP] * coef)\n",
    "        w = int(values[i, cv2.CC_STAT_WIDTH] * coef)\n",
    "        h = int(values[i, cv2.CC_STAT_HEIGHT] * coef)\n",
    "        slots.append([x1, y1, w, h])\n",
    "\n",
    "    return slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53d2d856-51a2-4880-a950-a063dc008466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Video output path and settings\n",
    "output_video_path = 'processed_parking_lot_video.avi'\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "frame_rate = cap.get(cv2.CAP_PROP_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b895bc5c-3809-403a-90fc-9c841617f760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the VideoWriter to save the output video\n",
    "video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'XVID'), frame_rate, (frame_width, frame_height))\n",
    "\n",
    "# Get parking spot bounding boxes\n",
    "spots = get_parking_spots_bboxes(connected_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df849d2e-ccbb-4871-8070-e97498871298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize variables for the processing loop\n",
    "spots_status = [None for _ in spots]\n",
    "diffs = [None for _ in spots]\n",
    "previous_frame = None\n",
    "\n",
    "frame_nmr = 0\n",
    "ret = True\n",
    "step = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6ed36cd-0c85-4396-b49c-c46ad5b0a197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process the video frame-by-frame\n",
    "while ret:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If a valid frame is read\n",
    "    if ret:\n",
    "        # Every 'step' frames, calculate the difference from the previous frame\n",
    "        if frame_nmr % step == 0 and previous_frame is not None:\n",
    "            for spot_idx, spot in enumerate(spots):\n",
    "                x1, y1, w, h = spot\n",
    "                spot_crop = frame[y1:y1 + h, x1:x1 + w]\n",
    "                diffs[spot_idx] = np.abs(np.mean(spot_crop) - np.mean(previous_frame[y1:y1 + h, x1:x1 + w]))\n",
    "\n",
    "        # Determine spot status based on differences\n",
    "        if frame_nmr % step == 0:\n",
    "            if previous_frame is None:\n",
    "                arr_ = range(len(spots))\n",
    "            else:\n",
    "                arr_ = [j for j in np.argsort(diffs) if diffs[j] / np.amax(diffs) > 0.4]\n",
    "\n",
    "            for spot_idx in arr_:\n",
    "                spot = spots[spot_idx]\n",
    "                x1, y1, w, h = spot\n",
    "                spot_crop = frame[y1:y1 + h, x1:x1 + w]\n",
    "                spot_status = empty_or_not(spot_crop)\n",
    "                spots_status[spot_idx] = spot_status\n",
    "\n",
    "        # Keep a copy of the frame for comparison\n",
    "        if frame_nmr % step == 0:\n",
    "            previous_frame = frame.copy()\n",
    "\n",
    "        # Draw rectangles around parking spots based on their status\n",
    "        for spot_idx, spot in enumerate(spots):\n",
    "            x1, y1, w, h = spot\n",
    "            if spots_status[spot_idx]:\n",
    "                frame = cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2)\n",
    "            else:\n",
    "                frame = cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 0, 255), 2)\n",
    "\n",
    "        # Write text and draw on the frame\n",
    "        cv2.rectangle(frame, (80, 20), (550, 80), (0, 0, 0), -1)\n",
    "        cv2.putText(frame, f'Available spots: {sum(spots_status)} / {len(spots_status)}', (100, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "        # Save the processed frame to the output video\n",
    "        video_writer.write(frame)\n",
    "\n",
    "    frame_nmr += 1\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
